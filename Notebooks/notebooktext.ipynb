{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ilyas\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# libraries for dataset preparation, feature engineering, model training \n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import preprocessing, linear_model, svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import ast\n",
    "import os\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import GRU, Dropout, MaxPooling1D, Conv1D, Flatten, BatchNormalization, GlobalMaxPool1D\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import (classification_report, \n",
    "                             precision_recall_fscore_support, \n",
    "                             accuracy_score)\n",
    "\n",
    "from keras.preprocessing import text, sequence\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../Data/train2/txt/AAAWNA.txt</td>\n",
       "      <td>REPUBLIQUE FRANCAISE Nationalité Française Car...</td>\n",
       "      <td>C2</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../Data/train2/txt/AAUVHC.txt</td>\n",
       "      <td>17 08 12 15:10 MLTC 00212537680032 p.2 في ليلة...</td>\n",
       "      <td>C3</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../Data/train2/txt/ABBABC.txt</td>\n",
       "      <td>Hi sweetie ! just a quick note to say ... HAPP...</td>\n",
       "      <td>C3</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../Data/train2/txt/ABBABD.txt</td>\n",
       "      <td>BE THE CHANGE YOU WANT TO SEE IN THE WORLD !</td>\n",
       "      <td>C3</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../Data/train2/txt/ABBABE.txt</td>\n",
       "      <td>scenario 1 Bridgewater House Barlow Street Wor...</td>\n",
       "      <td>C3</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>../Data/train2/txt/ABBABF.txt</td>\n",
       "      <td>remember - Jane got 100 % on the vast test she...</td>\n",
       "      <td>C3</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>../Data/train2/txt/ABBACE.txt</td>\n",
       "      <td>- get map from hostel - get Euros visit eat . ...</td>\n",
       "      <td>C3</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>../Data/train2/txt/ABBADF.txt</td>\n",
       "      <td>Hi Lucie, The postman left your delivery with ...</td>\n",
       "      <td>C3</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>../Data/train2/txt/ABBAGH.txt</td>\n",
       "      <td>To whom it may concern, I am writing to inform...</td>\n",
       "      <td>C3</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>../Data/train2/txt/ABBAJL.txt</td>\n",
       "      <td>Dear Jay, I hope ¤{eveything/everything}¤ is o...</td>\n",
       "      <td>C3</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Filename  \\\n",
       "0  ../Data/train2/txt/AAAWNA.txt   \n",
       "1  ../Data/train2/txt/AAUVHC.txt   \n",
       "2  ../Data/train2/txt/ABBABC.txt   \n",
       "3  ../Data/train2/txt/ABBABD.txt   \n",
       "4  ../Data/train2/txt/ABBABE.txt   \n",
       "5  ../Data/train2/txt/ABBABF.txt   \n",
       "6  ../Data/train2/txt/ABBACE.txt   \n",
       "7  ../Data/train2/txt/ABBADF.txt   \n",
       "8  ../Data/train2/txt/ABBAGH.txt   \n",
       "9  ../Data/train2/txt/ABBAJL.txt   \n",
       "\n",
       "                                                Text Class Language  \n",
       "0  REPUBLIQUE FRANCAISE Nationalité Française Car...    C2       fr  \n",
       "1  17 08 12 15:10 MLTC 00212537680032 p.2 في ليلة...    C3       ar  \n",
       "2  Hi sweetie ! just a quick note to say ... HAPP...    C3       en  \n",
       "3       BE THE CHANGE YOU WANT TO SEE IN THE WORLD !    C3       en  \n",
       "4  scenario 1 Bridgewater House Barlow Street Wor...    C3       en  \n",
       "5  remember - Jane got 100 % on the vast test she...    C3       en  \n",
       "6  - get map from hostel - get Euros visit eat . ...    C3       en  \n",
       "7  Hi Lucie, The postman left your delivery with ...    C3       en  \n",
       "8  To whom it may concern, I am writing to inform...    C3       en  \n",
       "9  Dear Jay, I hope ¤{eveything/everything}¤ is o...    C3       en  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataframe from CSV file\n",
    "df_train = pd.read_csv(\"../Data/train2/train_text.csv\", sep=\"\\t\")\n",
    "df_dev = pd.read_csv(\"../Data/dev2/dev_text.csv\", sep=\"\\t\")\n",
    "df_train[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (6129,)\n",
      "X_dev:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train['Text']\n",
    "y_train = df_train['Class']\n",
    "X_dev = df_dev['Text']\n",
    "y_dev = df_dev['Class']\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_dev = encoder.fit_transform(y_dev)\n",
    "\n",
    "print('X_train: ',X_train.shape)\n",
    "print('X_dev: ',X_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create document vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=3000,analyzer='word', token_pattern=r'\\w{1,}')\n",
    "vectorizer.fit(df_train['Text'])\n",
    "\n",
    "X_train_counts = vectorizer.transform(X_train)\n",
    "X_dev_counts = vectorizer.transform(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naive Bayes classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Validation du classifieur: \n",
      "\n",
      "Score :  0.726\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts,y_train)\n",
    "score_dev = clf.score(X_dev_counts,y_dev)\n",
    "print(' - Validation du classifieur: \\n')\n",
    "print('Score : ',score_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Validation du classifieur: \n",
      "\n",
      "Score :  0.891\n"
     ]
    }
   ],
   "source": [
    "lc = linear_model.LogisticRegression()\n",
    "lc.fit(X_train_counts,y_train)\n",
    "score_dev = lc.score(X_dev_counts,y_dev)\n",
    "print(' - Validation du classifieur: \\n')\n",
    "print('Score : ',score_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CNN classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(train_raw_text, test_raw_text):\n",
    "    \n",
    "    tokenizer = text.Tokenizer(num_words=MAX_FEATURES, )\n",
    "\n",
    "    tokenizer.fit_on_texts(list(train_raw_text))\n",
    "    train_tokenized = tokenizer.texts_to_sequences(train_raw_text)\n",
    "    test_tokenized = tokenizer.texts_to_sequences(test_raw_text)\n",
    "    return sequence.pad_sequences(train_tokenized, maxlen=MAX_TEXT_LENGTH), \\\n",
    "           sequence.pad_sequences(test_tokenized, maxlen=MAX_TEXT_LENGTH)\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    inp = Input(shape=(MAX_TEXT_LENGTH,))\n",
    "    model = Embedding(MAX_FEATURES, EMBED_SIZE)(inp)\n",
    "    \n",
    "    model = Conv1D(filters=32, kernel_size=7, padding='same', activation='relu')(model)\n",
    "    model = MaxPooling1D(pool_size=2)(model)\n",
    "    model = BatchNormalization(axis=1)(model)\n",
    "    model = Dropout(0.2)(model)\n",
    "    \n",
    "    model = Conv1D(filters=64, kernel_size=5, padding='same', activation='relu')(model)\n",
    "    model = MaxPooling1D(pool_size=3)(model)\n",
    "    model = BatchNormalization(axis=1)(model)\n",
    "    model = Dropout(0.3)(model)\n",
    "    \n",
    "    model = Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')(model)\n",
    "    model = MaxPooling1D(pool_size=5)(model)\n",
    "    model = BatchNormalization(axis=1)(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    \n",
    "    model = Flatten()(model)\n",
    "    model = Dense(250, activation=\"relu\")(model)\n",
    "    model = Dense(5, activation=\"softmax\")(model)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=model)\n",
    "    \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "6129 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 500, 32)           16000     \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 500, 32)           7200      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 250, 32)           1000      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 250, 64)           10304     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 83, 64)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 83, 64)            332       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 83, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 83, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16, 128)           64        \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 250)               512250    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 573,109\n",
      "Trainable params: 572,411\n",
      "Non-trainable params: 698\n",
      "_________________________________________________________________\n",
      "Train on 5516 samples, validate on 613 samples\n",
      "Epoch 1/100\n",
      "5516/5516 [==============================] - 46s 8ms/step - loss: 1.4646 - acc: 0.4239 - val_loss: 1.1937 - val_acc: 0.5693\n",
      "Epoch 2/100\n",
      "5516/5516 [==============================] - 39s 7ms/step - loss: 1.1447 - acc: 0.5007 - val_loss: 1.0476 - val_acc: 0.6460\n",
      "Epoch 3/100\n",
      "5516/5516 [==============================] - 38s 7ms/step - loss: 0.8658 - acc: 0.6483 - val_loss: 0.7853 - val_acc: 0.7292\n",
      "Epoch 4/100\n",
      "5516/5516 [==============================] - 38s 7ms/step - loss: 0.7063 - acc: 0.7141 - val_loss: 0.6491 - val_acc: 0.7488\n",
      "Epoch 5/100\n",
      "5516/5516 [==============================] - 39s 7ms/step - loss: 0.5962 - acc: 0.7565 - val_loss: 0.5786 - val_acc: 0.7765\n",
      "Epoch 6/100\n",
      "5516/5516 [==============================] - 39s 7ms/step - loss: 0.5505 - acc: 0.7799 - val_loss: 0.5922 - val_acc: 0.7749\n",
      "Epoch 7/100\n",
      "5516/5516 [==============================] - 35s 6ms/step - loss: 0.4965 - acc: 0.8096 - val_loss: 0.5253 - val_acc: 0.8026\n",
      "Epoch 8/100\n",
      "5516/5516 [==============================] - 36s 7ms/step - loss: 0.4580 - acc: 0.8261 - val_loss: 0.6754 - val_acc: 0.7635\n",
      "Epoch 9/100\n",
      "5516/5516 [==============================] - 36s 7ms/step - loss: 0.4366 - acc: 0.8319 - val_loss: 0.6551 - val_acc: 0.7847\n",
      "Epoch 10/100\n",
      "5516/5516 [==============================] - 36s 7ms/step - loss: 0.4121 - acc: 0.8481 - val_loss: 0.5272 - val_acc: 0.8108\n",
      "Epoch 11/100\n",
      "5516/5516 [==============================] - 36s 7ms/step - loss: 0.3668 - acc: 0.8666 - val_loss: 0.5741 - val_acc: 0.8059\n",
      "Epoch 12/100\n",
      "5516/5516 [==============================] - 36s 7ms/step - loss: 0.3319 - acc: 0.8793 - val_loss: 0.4886 - val_acc: 0.8418\n",
      "Epoch 13/100\n",
      "5516/5516 [==============================] - 36s 6ms/step - loss: 0.3156 - acc: 0.8796 - val_loss: 0.5161 - val_acc: 0.8157\n",
      "Epoch 14/100\n",
      "5516/5516 [==============================] - 37s 7ms/step - loss: 0.3129 - acc: 0.8883 - val_loss: 0.5285 - val_acc: 0.8108\n",
      "Epoch 15/100\n",
      "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2875 - acc: 0.8963 - val_loss: 0.5232 - val_acc: 0.8385\n",
      "Epoch 16/100\n",
      "5516/5516 [==============================] - 37s 7ms/step - loss: 0.2593 - acc: 0.9063 - val_loss: 0.5254 - val_acc: 0.8369\n",
      "Epoch 17/100\n",
      "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2523 - acc: 0.9081 - val_loss: 0.5267 - val_acc: 0.8434\n",
      "Epoch 18/100\n",
      "5516/5516 [==============================] - 37s 7ms/step - loss: 0.2188 - acc: 0.9235 - val_loss: 0.5364 - val_acc: 0.8499\n",
      "Epoch 19/100\n",
      "5516/5516 [==============================] - 37s 7ms/step - loss: 0.2027 - acc: 0.9235 - val_loss: 0.5403 - val_acc: 0.8515\n",
      "Epoch 20/100\n",
      "5516/5516 [==============================] - 37s 7ms/step - loss: 0.1996 - acc: 0.9282 - val_loss: 0.5403 - val_acc: 0.8434\n",
      "Epoch 21/100\n",
      "5516/5516 [==============================] - 36s 7ms/step - loss: 0.1943 - acc: 0.9317 - val_loss: 0.5508 - val_acc: 0.8483\n",
      "Epoch 22/100\n",
      "5516/5516 [==============================] - 36s 7ms/step - loss: 0.1890 - acc: 0.9315 - val_loss: 0.5656 - val_acc: 0.8450\n",
      "Epoch 23/100\n",
      "5516/5516 [==============================] - 37s 7ms/step - loss: 0.1809 - acc: 0.9344 - val_loss: 0.5593 - val_acc: 0.8483\n",
      "Epoch 24/100\n",
      "5516/5516 [==============================] - 40s 7ms/step - loss: 0.1828 - acc: 0.9355 - val_loss: 0.5503 - val_acc: 0.8499\n",
      "Epoch 25/100\n",
      "5516/5516 [==============================] - 45s 8ms/step - loss: 0.1774 - acc: 0.9364 - val_loss: 0.5528 - val_acc: 0.8499\n",
      "Epoch 26/100\n",
      "5516/5516 [==============================] - 45s 8ms/step - loss: 0.1777 - acc: 0.9387 - val_loss: 0.5609 - val_acc: 0.8499\n",
      "Epoch 27/100\n",
      "5516/5516 [==============================] - 32s 6ms/step - loss: 0.1824 - acc: 0.9367 - val_loss: 0.5625 - val_acc: 0.8532\n",
      "Epoch 28/100\n",
      "5516/5516 [==============================] - 35s 6ms/step - loss: 0.1808 - acc: 0.9338 - val_loss: 0.5622 - val_acc: 0.8499\n",
      "Epoch 29/100\n",
      "5516/5516 [==============================] - 30s 5ms/step - loss: 0.1786 - acc: 0.9349 - val_loss: 0.5619 - val_acc: 0.8515\n",
      "Epoch 30/100\n",
      "5516/5516 [==============================] - 28s 5ms/step - loss: 0.1743 - acc: 0.9385 - val_loss: 0.5598 - val_acc: 0.8515\n",
      "Epoch 31/100\n",
      "5516/5516 [==============================] - 29s 5ms/step - loss: 0.1808 - acc: 0.9353 - val_loss: 0.5590 - val_acc: 0.8515\n",
      "Epoch 32/100\n",
      "2176/5516 [==========>...................] - ETA: 19s - loss: 0.1849 - acc: 0.9352"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "MAX_FEATURES = 500\n",
    "MAX_TEXT_LENGTH = 500\n",
    "EMBED_SIZE  = 32\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "# Get the list of different classes\n",
    "CLASSES_LIST = np.unique(y_train)\n",
    "n_out = len(CLASSES_LIST)\n",
    "print(CLASSES_LIST)\n",
    "\n",
    "# Convert class string to index\n",
    "train_y_cat = np_utils.to_categorical(y_train, n_out)\n",
    "test_y_cat = np_utils.to_categorical(y_dev, n_out)\n",
    "\n",
    "# get the textual data in the correct format for NN\n",
    "x_vec_train, x_vec_test = get_train_test(X_train, X_dev)\n",
    "print(len(x_vec_train), len(x_vec_test))\n",
    "\n",
    "# define the NN topology\n",
    "model = get_model()\n",
    "\n",
    "# Create callbacks\n",
    "filepath = 'model_cnn' + '.hdf5'\n",
    "multi_checkpointer = ModelCheckpoint(filepath=filepath, verbose=0)\n",
    "multi_lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=0, factor=0.2)\n",
    "\n",
    "# Train \n",
    "model.fit(x_vec_train, train_y_cat,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS, verbose=1, validation_split=VALIDATION_SPLIT,callbacks=[multi_checkpointer,multi_lr_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.792\n",
      "p r f1 79.2 79.20 79.200\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.90      0.94       146\n",
      "          1       0.91      0.85      0.88       426\n",
      "          2       0.57      0.83      0.67       212\n",
      "          3       0.76      0.59      0.66       169\n",
      "          4       0.86      0.51      0.64        47\n",
      "\n",
      "avg / total       0.82      0.79      0.80      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Matrice de probabilitées d'appartenance à chaque classe\n",
    "y_predicted = model.predict(x_vec_test)\n",
    "\n",
    "# Attribution de la classe qui a la plus probable\n",
    "y_pred = np.zeros(len(y_dev))\n",
    "for i in range(len(y_predicted)):\n",
    "    y_pred[i] = np.argmax(y_predicted[i])\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_pred, y_dev))\n",
    "\n",
    "p, r, f1, s = precision_recall_fscore_support(y_dev, y_pred, \n",
    "                                              average='micro',\n",
    "                                              labels=[x for x in \n",
    "                                                      np.unique(y_train) \n",
    "                                                      if x not in ['CSDECMOTV']])\n",
    "\n",
    "print('p r f1 %.1f %.2f %.3f' % (np.average(p, weights=s)*100.0, \n",
    "                                 np.average(r, weights=s)*100.0, \n",
    "                                 np.average(f1, weights=s)*100.0))\n",
    "\n",
    "\n",
    "print(classification_report(y_dev, y_pred, labels=[x for x in \n",
    "                                                       np.unique(y_train) \n",
    "                                                       if x not in ['CSDECMOTV']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['Text']\n",
    "y_train = df_train['Language']\n",
    "X_dev = df_dev['Text']\n",
    "y_dev = df_dev['Language']\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_dev = encoder.fit_transform(y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naive bayes classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts,y_train)\n",
    "score_dev = clf.score(X_dev_counts,y_dev)\n",
    "print(' - Validation du classifieur: \\n')\n",
    "print('Score : ',score_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = linear_model.LogisticRegression()\n",
    "lc.fit(X_train_counts,y_train)\n",
    "score_dev = lc.score(X_dev_counts,y_dev)\n",
    "print(' - Validation du classifieur: \\n')\n",
    "print('Score : ',score_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CNN classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 500\n",
    "MAX_TEXT_LENGTH = 500\n",
    "EMBED_SIZE  = 32\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "# Get the list of different classes\n",
    "CLASSES_LIST = np.unique(y_train)\n",
    "n_out = len(CLASSES_LIST)\n",
    "print(CLASSES_LIST)\n",
    "\n",
    "# Convert class string to index\n",
    "train_y_cat = np_utils.to_categorical(y_train, n_out)\n",
    "test_y_cat = np_utils.to_categorical(y_dev, n_out)\n",
    "\n",
    "# get the textual data in the correct format for NN\n",
    "x_vec_train, x_vec_test = get_train_test(X_train, X_dev)\n",
    "print(len(x_vec_train), len(x_vec_test))\n",
    "\n",
    "# define the NN topology\n",
    "model = get_model()\n",
    "\n",
    "# Create callbacks\n",
    "filepath = 'model_cnn' + '.hdf5'\n",
    "multi_checkpointer = ModelCheckpoint(filepath=filepath, verbose=0)\n",
    "multi_lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=0, factor=0.2)\n",
    "\n",
    "# Train \n",
    "model.fit(x_vec_train, train_y_cat,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS, verbose=1, validation_split=VALIDATION_SPLIT,callbacks=[multi_checkpointer,multi_lr_reduction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
